{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading \n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device, torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device= torch.device(\"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CUDA Out of Memory, use CPU\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Slow Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "SlowFastNet = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)\n",
    "SlowFastNet = SlowFastNet.eval()\n",
    "SlowFastNet = SlowFastNet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "\n",
    "json_url = \"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\"\n",
    "json_filename = \"kinetics_classnames.json\"\n",
    "try: urllib.URLopener().retrieve(json_url, json_filename)\n",
    "except: urllib.request.urlretrieve(json_url, json_filename)\n",
    "    \n",
    "with open(json_filename, \"r\") as f:\n",
    "    kinetics_classnames = json.load(f)\n",
    "\n",
    "# Create an id to label name mapping\n",
    "kinetics_id_to_classname = {}\n",
    "for k, v in kinetics_classnames.items():\n",
    "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\envs\\PyTorch_1.9.0\\lib\\site-packages\\torchvision\\transforms\\_functional_video.py:5: UserWarning: The _functional_video module is deprecated. Please use the functional module instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\envs\\PyTorch_1.9.0\\lib\\site-packages\\torchvision\\transforms\\_transforms_video.py:25: UserWarning: The _transforms_video module is deprecated. Please use the transforms module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import NormalizeVideo\n",
    "from pytorchvideo.transforms import UniformTemporalSubsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow Fast parameters\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "slowfast_alpha = 4\n",
    "num_frames = 32\n",
    "sampling_rate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SlowFastTransform=Compose(\n",
    "    [\n",
    "        UniformTemporalSubsample(num_frames),\n",
    "        Lambda(lambda x: x/255.0),\n",
    "        NormalizeVideo(mean, std),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read img frames from web cam using Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read web cam thread\n",
    "def Read_web_cam():\n",
    "    global __ret, __frame\n",
    "    t1 = threading.currentThread()\n",
    "    while getattr(t1, \"do_run\", True):\n",
    "        __ret, __frame = __cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used by Predict_action thread\n",
    "def Collect_img_frames_and_predict_action (NoFrames):\n",
    "    #collect No. of image frames from web cam\n",
    "    #return a list [img1, img2, ...], img = torch (3, H, W)\n",
    "    global __ret, __frame\n",
    "    imgLst =[]\n",
    "    frame_count = 1\n",
    "    while (frame_count<= NoFrames):\n",
    "        if __ret == True:\n",
    "            transform = transforms.Compose([transforms.ToTensor()]) \n",
    "            img = transform(__frame) # torch (3, H, W)\n",
    "            imgLst.append(img)\n",
    "            frame_count +=1\n",
    "    \n",
    "    # pass image frames to SlowFast\n",
    "    ImgsTensor = torch.stack(imgLst)  #stach a list of tensors \n",
    "    ImgsTensor = ImgsTensor.permute(1, 0, 2, 3)\n",
    "    fast_pathway = SlowFastTransform(ImgsTensor)\n",
    "    slow_pathway = torch.index_select(\n",
    "        fast_pathway,\n",
    "        1,\n",
    "        torch.linspace(\n",
    "            0, fast_pathway.shape[1] - 1, fast_pathway.shape[1] // slowfast_alpha\n",
    "        ).long(),\n",
    "    )\n",
    "    SlowFastInputFrames = [slow_pathway, fast_pathway]\n",
    "    SlowFastInputFrames = [i.to(device)[None, ...] for i in SlowFastInputFrames]\n",
    "    preds = SlowFastNet(SlowFastInputFrames)\n",
    "    post_act = torch.nn.Softmax(dim=1)\n",
    "    preds = post_act(preds)\n",
    "    del SlowFastInputFrames\n",
    "    torch.cuda.empty_cache() #release GPU memory cache\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate No of frames need to be sent to SlowFast\n",
    "SlowFastFrames = num_frames * sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread to predict action\n",
    "def Predict_action():\n",
    "    #every 30 seconds, collect image frames and send to SlowFast\n",
    "    t2 = threading.currentThread()\n",
    "    while getattr(t2, \"do_run\", True):\n",
    "        start = time.time()\n",
    "        time_to_start = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time.localtime())\n",
    "        print(time_to_start, end =\"==>\")\n",
    "        preds= Collect_img_frames_and_predict_action (SlowFastFrames)\n",
    "        for i, score in enumerate(preds[0].topk(k=5)[0].tolist()):\n",
    "            if(score >= 0.1):\n",
    "                ActionID = preds[0].topk(k=5)[1][i] \n",
    "                ActionLabel = kinetics_id_to_classname[int(ActionID)]\n",
    "                print(ActionLabel, round(score, 2), end=\",  \")\n",
    "        print(\"\\n\")\n",
    "        timePassed = time.time()-start\n",
    "        #time.sleep(30-timePassed)\n",
    "        if(timePassed<10):\n",
    "            time.sleep(10-timePassed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/08/2022, 15:46:19==>singing 0.51,  dancing ballet 0.38,  \n",
      "\n",
      "01/08/2022, 15:46:29==>singing 0.45,  dancing ballet 0.44,  \n",
      "\n",
      "01/08/2022, 15:46:39==>singing 0.45,  dancing ballet 0.45,  \n",
      "\n",
      "01/08/2022, 15:46:49==>singing 0.47,  dancing ballet 0.41,  \n",
      "\n",
      "01/08/2022, 15:46:59==>dancing ballet 0.44,  singing 0.44,  \n",
      "\n",
      "01/08/2022, 15:47:09==>singing 0.69,  dancing ballet 0.26,  \n",
      "\n",
      "01/08/2022, 15:47:19==>singing 0.63,  dancing ballet 0.31,  \n",
      "\n",
      "01/08/2022, 15:47:29==>singing 0.59,  dancing ballet 0.36,  \n",
      "\n",
      "01/08/2022, 15:47:39==>singing 0.61,  dancing ballet 0.33,  \n",
      "\n",
      "01/08/2022, 15:47:49==>singing 0.56,  dancing ballet 0.36,  \n",
      "\n",
      "01/08/2022, 15:47:59==>singing 0.65,  dancing ballet 0.3,  \n",
      "\n",
      "01/08/2022, 15:48:09==>singing 0.62,  dancing ballet 0.3,  \n",
      "\n",
      "01/08/2022, 15:48:19==>singing 0.57,  dancing ballet 0.38,  \n",
      "\n",
      "01/08/2022, 15:48:29==>singing 0.55,  dancing ballet 0.39,  \n",
      "\n",
      "01/08/2022, 15:48:39==>singing 0.57,  dancing ballet 0.37,  \n",
      "\n",
      "01/08/2022, 15:48:49==>singing 0.67,  dancing ballet 0.27,  \n",
      "\n",
      "01/08/2022, 15:48:59==>singing 0.61,  dancing ballet 0.23,  \n",
      "\n",
      "01/08/2022, 15:49:09==>singing 0.57,  dancing ballet 0.38,  \n",
      "\n",
      "01/08/2022, 15:49:19==>singing 0.65,  dancing ballet 0.23,  \n",
      "\n",
      "01/08/2022, 15:49:29==>singing 0.58,  dancing ballet 0.36,  \n",
      "\n",
      "01/08/2022, 15:49:39==>singing 0.76,  dancing ballet 0.17,  \n",
      "\n",
      "01/08/2022, 15:49:49==>singing 0.58,  dancing ballet 0.37,  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#啟動 web cam, 以 global variables 紀錄, \n",
    "__cap = cv2.VideoCapture(0) \n",
    "__ret, __frame = __cap.read()\n",
    "\n",
    "# seperate thread to read image frames from web cam\n",
    "t1 = threading.Thread(target = Read_web_cam, args = ())\n",
    "t1.start()\n",
    "\n",
    "# seperate thread to collect image frames and send to SlowFast\n",
    "t2 = threading.Thread(target = Predict_action, args = ())\n",
    "t2.start()\n",
    "\n",
    "# main thread to display\n",
    "cv2.namedWindow(\"window\", cv2.WINDOW_NORMAL)\n",
    "while (True):\n",
    "    if __ret == True:\n",
    "        cv2.imshow(\"window\", __frame)\n",
    "    # Press Q on keyboard to exit\n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')):\n",
    "        t1.do_run = t2.do_run = False  #stop thread\n",
    "        break #break from while loop\n",
    "\n",
    "t1.join() #when thread finishes comes here\n",
    "t2.join()\n",
    "__cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
